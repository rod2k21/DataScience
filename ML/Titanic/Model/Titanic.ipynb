{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4feed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################LIBRERÍAS A UTILIZAR#############################\n",
    "##Procesamiento de Datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import os\n",
    "from pathlib import Path\n",
    "\n",
    "##Algoritmos de ML\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5e2c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\GitHub\\DataScience\\ML\\Titanic\\Dataset\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  WikiId  \\\n",
      "0  34.5      0      0   330911   7.8292   NaN        Q   928.0   \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  1297.0   \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q   518.0   \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  1303.0   \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S   871.0   \n",
      "\n",
      "                                        Name_wiki  Age_wiki  \\\n",
      "0                                Kelly, Mr. James      19.0   \n",
      "1                              Wilkes, Mrs. Ellen      47.0   \n",
      "2                       Myles, Mr. Thomas Francis      63.0   \n",
      "3                                Wirz, Mr. Albert      27.0   \n",
      "4  Hirvonen, Mrs. Helga Elisabeth (née Lindqvist)      22.0   \n",
      "\n",
      "                      Hometown      Boarded                 Destination  \\\n",
      "0             Unknown, Ireland  Southampton               New York City   \n",
      "1  Penzance, Cornwall, England  Southampton             Akron, Ohio, US   \n",
      "2      Fermoy, Ireland[note 1]   Queenstown    Waban, Massachusetts, US   \n",
      "3           Uster, Switzerland  Southampton       Beloit, Wisconsin, US   \n",
      "4        Taalintehdas, Finland  Southampton  Monessen, Pennsylvania, US   \n",
      "\n",
      "  Lifeboat   Body  Class  \n",
      "0      NaN   70MB    3.0  \n",
      "1       16    NaN    3.0  \n",
      "2      NaN    NaN    2.0  \n",
      "3      NaN  131MB    3.0  \n",
      "4       15    NaN    3.0  \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1       0.0       3   \n",
      "1            2       1.0       1   \n",
      "2            3       1.0       3   \n",
      "3            4       1.0       1   \n",
      "4            5       0.0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare  ... Embarked WikiId  \\\n",
      "0      0         A/5 21171   7.2500  ...        S  691.0   \n",
      "1      0          PC 17599  71.2833  ...        C   90.0   \n",
      "2      0  STON/O2. 3101282   7.9250  ...        S  865.0   \n",
      "3      0            113803  53.1000  ...        S  127.0   \n",
      "4      0            373450   8.0500  ...        S  627.0   \n",
      "\n",
      "                                    Name_wiki Age_wiki  \\\n",
      "0                     Braund, Mr. Owen Harris     22.0   \n",
      "1  Cumings, Mrs. Florence Briggs (née Thayer)     35.0   \n",
      "2                       Heikkinen, Miss Laina     26.0   \n",
      "3          Futrelle, Mrs. Lily May (née Peel)     35.0   \n",
      "4                    Allen, Mr. William Henry     35.0   \n",
      "\n",
      "                             Hometown      Boarded  \\\n",
      "0          Bridgerule, Devon, England  Southampton   \n",
      "1              New York, New York, US    Cherbourg   \n",
      "2                  Jyväskylä, Finland  Southampton   \n",
      "3         Scituate, Massachusetts, US  Southampton   \n",
      "4  Birmingham, West Midlands, England  Southampton   \n",
      "\n",
      "                               Destination Lifeboat Body Class  \n",
      "0  Qu'Appelle Valley, Saskatchewan, Canada      NaN  NaN   3.0  \n",
      "1                   New York, New York, US        4  NaN   1.0  \n",
      "2                            New York City      14?  NaN   3.0  \n",
      "3              Scituate, Massachusetts, US        D  NaN   1.0  \n",
      "4                            New York City      NaN  NaN   3.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#############################IMPORTANDO DATA################################\n",
    "#print(os.environ['USERPROFILE'])\n",
    "data_folder = Path(\"/GitHub/DataScience/ML/Titanic/Dataset/\")\n",
    "print(data_folder)\n",
    "df_test = pd.read_csv(\"F:\" / data_folder / \"test.csv\")\n",
    "df_train = pd.read_csv(\"F:\" / data_folder / \"train.csv\")\n",
    "\n",
    "print(df_test.head())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de Datos:\n",
      "(418, 20)\n",
      "(891, 21)\n",
      "Tipos de Datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      " 11  WikiId       415 non-null    float64\n",
      " 12  Name_wiki    415 non-null    object \n",
      " 13  Age_wiki     415 non-null    float64\n",
      " 14  Hometown     415 non-null    object \n",
      " 15  Boarded      415 non-null    object \n",
      " 16  Destination  415 non-null    object \n",
      " 17  Lifeboat     157 non-null    object \n",
      " 18  Body         43 non-null     object \n",
      " 19  Class        415 non-null    float64\n",
      "dtypes: float64(5), int64(4), object(11)\n",
      "memory usage: 65.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      " 12  WikiId       889 non-null    float64\n",
      " 13  Name_wiki    889 non-null    object \n",
      " 14  Age_wiki     887 non-null    float64\n",
      " 15  Hometown     889 non-null    object \n",
      " 16  Boarded      889 non-null    object \n",
      " 17  Destination  889 non-null    object \n",
      " 18  Lifeboat     345 non-null    object \n",
      " 19  Body         87 non-null     object \n",
      " 20  Class        889 non-null    float64\n",
      "dtypes: float64(6), int64(4), object(11)\n",
      "memory usage: 146.3+ KB\n",
      "None\n",
      "Datos faltantes:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "WikiId           3\n",
      "Name_wiki        3\n",
      "Age_wiki         3\n",
      "Hometown         3\n",
      "Boarded          3\n",
      "Destination      3\n",
      "Lifeboat       261\n",
      "Body           375\n",
      "Class            3\n",
      "dtype: int64\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "WikiId           2\n",
      "Name_wiki        2\n",
      "Age_wiki         4\n",
      "Hometown         2\n",
      "Boarded          2\n",
      "Destination      2\n",
      "Lifeboat       546\n",
      "Body           804\n",
      "Class            2\n",
      "dtype: int64\n",
      "Estadísticas del DataSet:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch  \\\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000   \n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   \n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   \n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000   \n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000   \n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   \n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   \n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000   \n",
      "\n",
      "             Fare       WikiId    Age_wiki       Class  \n",
      "count  417.000000   415.000000  415.000000  415.000000  \n",
      "mean    35.627188   643.684337   29.616241    2.257831  \n",
      "std     55.907576   379.508988   13.400225    0.847577  \n",
      "min      0.000000     2.000000    0.170000    1.000000  \n",
      "25%      7.895800   316.500000   21.000000    1.000000  \n",
      "50%     14.454200   641.000000   27.000000    3.000000  \n",
      "75%     31.500000   965.500000   37.000000    3.000000  \n",
      "max    512.329200  1313.000000   67.000000    3.000000  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare       WikiId    Age_wiki       Class  \n",
      "count  891.000000  891.000000   889.000000  887.000000  889.000000  \n",
      "mean     0.381594   32.204208   665.466817   29.322063    2.307087  \n",
      "std      0.806057   49.693429   380.796997   13.930089    0.837713  \n",
      "min      0.000000    0.000000     1.000000    0.420000    1.000000  \n",
      "25%      0.000000    7.910400   336.000000   20.000000    2.000000  \n",
      "50%      0.000000   14.454200   672.000000   28.000000    3.000000  \n",
      "75%      0.000000   31.000000   996.000000   38.000000    3.000000  \n",
      "max      6.000000  512.329200  1314.000000   74.000000    3.000000  \n"
     ]
    }
   ],
   "source": [
    "###########################ENTENDIENDO LA DATA##############################\n",
    "#Verificar la cantidad de Datos en los DataSet\n",
    "print('Cantidad de Datos:')\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "\n",
    "#Verificar el tipo de Datos en ambos DataSet\n",
    "print('Tipos de Datos:')\n",
    "print(df_test.info())\n",
    "print(df_train.info())\n",
    "\n",
    "#Verificar Datos faltantes\n",
    "print('Datos faltantes:')\n",
    "print(pd.isnull(df_test).sum())\n",
    "print(pd.isnull(df_train).sum())\n",
    "\n",
    "#Verificar las estadísticas de cada DataSet\n",
    "print('Estadísticas del DataSet:')\n",
    "print(df_test.describe())\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcc12ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.272590361445783\n",
      "29.69911764705882\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "(417, 8)\n",
      "(889, 8)\n",
      "   PassengerId  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0          892       3    1   5      0      0   7.8292         0\n",
      "1          893       3    0   6      1      0   7.0000         1\n",
      "2          894       2    1   7      0      0   9.6875         0\n",
      "3          895       3    1   5      0      0   8.6625         1\n",
      "4          896       3    0   4      1      1  12.2875         1\n",
      "   Survived  Pclass  Sex Age  SibSp  Parch     Fare  Embarked\n",
      "0       0.0       3    1   4      1      0   7.2500       1.0\n",
      "1       1.0       1    0   5      1      0  71.2833       2.0\n",
      "2       1.0       3    0   5      0      0   7.9250       1.0\n",
      "3       1.0       1    0   5      1      0  53.1000       1.0\n",
      "4       0.0       3    1   5      0      0   8.0500       1.0\n"
     ]
    }
   ],
   "source": [
    "#############################PROCESANDO LA DATA#############################\n",
    "#Cambiar datos de sexo a números\n",
    "df_test['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "df_train['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
    "\n",
    "#Cambiar datos de embarque a números\n",
    "df_test['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)\n",
    "df_train['Embarked'].replace(['Q','S','C'],[0,1,2],inplace=True)\n",
    "\n",
    "#Reemplazar los Datos faltantes en la edad por la media de esta columna\n",
    "print(df_test['Age'].mean())\n",
    "print(df_train['Age'].mean())\n",
    "promedio = 30\n",
    "df_test['Age'] = df_test['Age'].replace(np.nan, promedio)\n",
    "df_train['Age'] = df_train['Age'].replace(np.nan, promedio)\n",
    "\n",
    "#Crear grupos por rango de edad\n",
    "#Grupos: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "names = ['1', '2', '3', '4', '5', '6', '7'] \n",
    "df_test['Age'] = pd.cut(df_test['Age'], bins, labels = names)\n",
    "df_train['Age'] = pd.cut(df_train['Age'], bins, labels = names)\n",
    "\n",
    "#Eliminar columna de \"Cabin\" ya que tiene muchos datos perdidos\n",
    "df_test.drop(['Cabin'], axis = 1, inplace = True)\n",
    "df_train.drop(['Cabin'], axis = 1, inplace = True)\n",
    "\n",
    "#Eliminar columnas que no se consideran necesarias para el análisis\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'WikiId', 'Name_wiki', 'Age_wiki', 'Hometown', 'Boarded', 'Destination', 'Lifeboat', 'Body', 'Class'], axis = 1)\n",
    "df_train = df_train.drop(['PassengerId', 'Name', 'Ticket', 'WikiId', 'Name_wiki', 'Age_wiki', 'Hometown', 'Boarded', 'Destination', 'Lifeboat', 'Body', 'Class'], axis = 1)\n",
    "\n",
    "#Eliminar filas con datos perdidos\n",
    "df_test.dropna(axis=0, how='any', inplace = True)\n",
    "df_train.dropna(axis=0, how='any', inplace = True)\n",
    "\n",
    "#Verificar los Datos\n",
    "print(pd.isnull(df_test).sum())\n",
    "print(pd.isnull(df_train).sum())\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "\n",
    "print(df_test.head())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f43abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 '4' ... 0 7.25 1.0]\n",
      " [1 0 '5' ... 0 71.2833 2.0]\n",
      " [3 0 '5' ... 0 7.925 1.0]\n",
      " ...\n",
      " [3 0 '5' ... 2 23.45 1.0]\n",
      " [1 1 '5' ... 0 30.0 2.0]\n",
      " [3 1 '5' ... 0 7.75 0.0]]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0.]\n",
      "Precision Regresion Logistica:\n",
      "0.8073136427566807\n",
      "Precision Soporte de Vectores:\n",
      "0.6736990154711674\n",
      "Precision Vecinos mas cercanos:\n",
      "0.8537271448663853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodrigr\\AppData\\Local\\Temp/ipykernel_27276/30224920.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x = np.array(df_train.drop(['Survived'], 1))\n"
     ]
    }
   ],
   "source": [
    "##########################APLICANDO ALGORITMOS DE ML########################\n",
    "#Armando Modelos\n",
    "\n",
    "#Separar el target con la infromación de supervivencia\n",
    "x = np.array(df_train.drop(['Survived'], 1))\n",
    "y = np.array(df_train['Survived'])\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "#Separar los Datos de entrenamiento\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "##Regresión logística\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "Y_pred = logreg.predict(x_test)\n",
    "print('Precision Regresion Logistica:')\n",
    "print(logreg.score(x_train, y_train))\n",
    "\n",
    "##Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "Y_pred = svc.predict(x_test)\n",
    "print('Precision Soporte de Vectores:')\n",
    "print(svc.score(x_train, y_train))\n",
    "\n",
    "##K Neighbors\n",
    "Knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "Knn.fit(x_train, y_train)\n",
    "Y_pred = Knn.predict(x_test)\n",
    "print('Precision Vecinos mas cercanos:')\n",
    "print(Knn.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9953c92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediccion Regresion Logistica:\n",
      "   PassengerId  Survived\n",
      "0          892       0.0\n",
      "1          893       0.0\n",
      "2          894       0.0\n",
      "3          895       0.0\n",
      "4          896       1.0\n",
      "Prediccion RSoporte de Vectores:\n",
      "   PassengerId  Survived\n",
      "0          892       0.0\n",
      "1          893       0.0\n",
      "2          894       0.0\n",
      "3          895       0.0\n",
      "4          896       0.0\n",
      "Prediccion Vecinos mas cercanos:\n",
      "   PassengerId  Survived\n",
      "0          892       1.0\n",
      "1          893       0.0\n",
      "2          894       0.0\n",
      "3          895       0.0\n",
      "4          896       1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#####################PREDICCIÓN UTILIZANDO LOS MODELOS#######################\n",
    "ids = df_test['PassengerId']\n",
    "\n",
    "##Regresión logística\n",
    "prediccion_logreg = logreg.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_logreg = pd.DataFrame({'PassengerId' : ids, 'Survived': prediccion_logreg })\n",
    "print('Prediccion Regresion Logistica:')\n",
    "print(out_logreg.head())\n",
    "\n",
    "##Support Vector Machines\n",
    "prediccion_svc = svc.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_svc = pd.DataFrame({'PassengerId' : ids, 'Survived': prediccion_svc })\n",
    "print('Prediccion RSoporte de Vectores:')\n",
    "print(out_svc.head())\n",
    "\n",
    "##K Neighbors\n",
    "prediccion_knn = Knn.predict(df_test.drop('PassengerId', axis=1))\n",
    "out_knn = pd.DataFrame({'PassengerId' : ids, 'Survived': prediccion_knn })\n",
    "print('Prediccion Vecinos mas cercanos:')\n",
    "print(out_knn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6cc3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
